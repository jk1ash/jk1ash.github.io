[{"content":"CUnit （单元测试框架），CUnit是一个用C语言编写、管理和运行单元测试的轻量级系统，它为C程序员提供了具有灵活多样用户界面的基本测试功能。\n环境安装 1 2 3 4 5 # 普通版本 apt install libcunit1 libcunit1-dev # ncurses版本 apt install libcunit1-ncurses libcunit1-ncurses-dev 四种模式输出简介 模式 平台 结果输出方式 使用的接口函数 介绍 Basic 所有 标准输出 #include \u0026ldquo;CUnit/Basic.h\u0026quot;CU_basic_set_mode(CU_BRM_VERBOSE);CU_basic_run_tests(); 结果输出到标准输出（stdout） Automated 所有 xml文件 #include \u0026ldquo;CUnit/Automated.h\u0026quot;CU_set_output_filename(\u0026ldquo;result\u0026rdquo;); CU_list_tests_to_file();CU_automated_run_tests(); 生成XML文件 Console 所有 交互式控制台 #include \u0026ldquo;CUnit/Console.h\u0026quot;CU_console_run_tests(); 比较灵活，可以选择只执行其中某一个测试用例 Curses Linux/Unix 交互式curses窗口 #include \u0026ldquo;CUnit/CUCurses.h\u0026quot;CU_curses_run_tests(); 跟Console类似，只不过是以Curses窗口的方式展示 注：Automated模式生成完XML文件之后，然后再将CUnit-List.dtd、CUnit-List.xsl、CUnit-Run.dtd、CUnit-Run.xsl（这几个文件在CUnit的源码包可以找到，在/usr/share/CUnit/目录下）和XML文件放到同一级目录，再用浏览器打开，就可以看到界面了。\n例子 1.添加测试suite 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * @description: 测试单元初始化函数 */ int initializeSuite() { printf(\u0026#34;\\n--- Start CUnit Test ---\\n\u0026#34;); return 0; } /** * @description: 测试单元释放函数 */ int finalizeSuite() { printf(\u0026#34;\\n--- Finish CUnit Test ---\\n\u0026#34;); return 0; } 2.添加测试用例case 1 2 3 4 5 6 7 8 9 10 11 12 //case1 void test_1_1() { /* 断言函数返回是否与预期相同 */ CU_ASSERT_EQUAL_FATAL(3, sum(1,2)); } //case2 void test_1_2() { CU_ASSERT_EQUAL_FATAL(1, sub(2,1)); } 3.创建测试模块 将之前创建的suite和case添加到模块中，可添加多个suite和case。 模块不是必须的，直接将suite和case添加到主函数也可以实现测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 /** * @description: 构建单元测试套件与用例 * @return CU_ErrorCode:cunit错误码 */ CU_ErrorCode TestModule() { CU_pSuite pSuite1 = NULL; pSuite1 = CU_add_suite(\u0026#34;Suite1\u0026#34;, initializeSuite, finalizeSuite); //检测注册Suite情况 if (NULL == pSuite1) { CU_cleanup_registry(); return CU_get_error(); } /** * 添加当前套件的测试用例 * Test_1-1：用例1-1名 test_1_1：用例函数 */ if (NULL == CU_add_test(pSuite1, \u0026#34;Test_1-1\u0026#34;, test_1_1)) { CU_cleanup_registry(); return CU_get_error(); } if (NULL == CU_add_test(pSuite1, \u0026#34;Test_1-2\u0026#34;, test_1_2)) { CU_cleanup_registry(); return CU_get_error(); } return CUE_SUCCESS; } 4.测试主函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \u0026lt;CUnit/Basic.h\u0026gt; #include \u0026lt;CUnit/CUnit.h\u0026gt; int main(int argc, char const *argv[]) { // 初始化测试注册表 if (CUE_SUCCESS != CU_initialize_registry()) { return CU_get_error(); } //检测是否在执行 assert(!CU_is_test_running()); //调用测试模块完成测试用例 if (CUE_SUCCESS != TestModule()) { CU_cleanup_registry(); return CU_get_error(); } // 设置运行模式 /*** 运行结果产成XML文件的模式******** CU_set_output_filename(\u0026#34;result\u0026#34;); CU_list_tests_to_file(); CU_automated_run_tests(); ***********************************/ // CU_console_run_tests(); /* 控制台交互模式 */ // CU_basic_run_tests(); /* 控制台直接输出 */ CU_curses_run_tests(); /* ncurses交互模式 */ //清除注册信息完成单元测试 CU_cleanup_registry(); return EXIT_SUCCESS; } CUint断言 以下断言可根据测试选择的不同判断条件来抛出异常，以达到单元测试的目的\n包含头文件 #include \u0026lt;CUnit/CUnit.h\u0026gt;\n断言 含义 CU_ASSERT(int expression)CU_ASSERT_FATAL(int expression)CU_TEST(int expression)CU_TEST_FATAL(int expression) 断言表达式为TRUE（非零） CU_ASSERT_TRUE(value)CU_ASSERT_TRUE_FATAL(value) 断言值为真（非零） CU_ASSERT_FALSE(value)CU_ASSERT_FALSE_FATAL(value) 断言值为假（零） CU_ASSERT_EQUAL(actual, expected)CU_ASSERT_EQUAL_FATAL(actual, expected) 断言实际值==期望值 CU_ASSERT_NOT_EQUAL(actual, expected))CU_ASSERT_NOT_EQUAL_FATAL(actual, expected) 断言实际值!=期望值 CU_ASSERT_PTR_EQUAL(actual, expected)CU_ASSERT_PTR_EQUAL_FATAL(actual, expected) 断言指针实际==期待 CU_ASSERT_PTR_NOT_EQUAL(actual, expected)CU_ASSERT_PTR_NOT_EQUAL_FATAL(actual, expected) 断言指针实际!=期待 CU_ASSERT_PTR_NULL(value)CU_ASSERT_PTR_NULL_FATAL(value) 指针值==NULL CU_ASSERT_PTR_NOT_NULL(value)CU_ASSERT_PTR_NOT_NULL_FATAL(value) 指针值!=NULL CU_ASSERT_STRING_EQUAL(actual, expected)CU_ASSERT_STRING_EQUAL_FATAL(actual, expected) 断言实际字符串与预期字符串相等 CU_ASSERT_STRING_NOT_EQUAL(actual, expected)CU_ASSERT_STRING_NOT_EQUAL_FATAL(actual, expected) 断言实际字符串与预期字符串不等 CU_ASSERT_NSTRING_EQUAL(actual, expected, count)CU_ASSERT_NSTRING_EQUAL_FATAL(actual, expected, count) 断言实际和预期的第一个计数字符相同 CU_ASSERT_NSTRING_NOT_EQUAL(actual, expected, count)CU_ASSERT_NSTRING_NOT_EQUAL_FATAL(actual, expected, count) 断言实际和预期的第一个计数字符不同 CU_ASSERT_DOUBLE_EQUAL(actual, expected, granularity)CU_ASSERT_DOUBLE_EQUAL_FATAL(actual, expected, granularity) 断言（实际-预期）\u0026lt;=（粒度） 此断言必须链接到数学库。 CU_ASSERT_DOUBLE_NOT_EQUAL(actual, expected, granularity)CU_ASSERT_DOUBLE_NOT_EQUAL_FATAL(actual, expected, granularity) 断言（实际-预期）\u0026gt;（粒度） 此断言必须链接到数学库。 CU_PASS(message) 用指定的消息注册传递断言。不执行逻辑测试。 CU_FAIL(message)CU_FAIL_FATAL(message) 用指定的消息注册失败的断言。不执行逻辑测试。 ","date":"2023-01-01T00:00:00Z","permalink":"https://blog.jklash.com/p/c%E8%AF%AD%E8%A8%80%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","title":"C语言单元测试"},{"content":"学习docker过程中的笔记整理\n安装 本地安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # install tools for install key sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # download official docker key curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # verify you have the docker key fingerprint apt-key fingerprint 0EBFCD88 # add docker repo add-apt-repository \\ \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\u0026#34; # update repo for docker apt update # install docker.io apt -y install docker-ce docker-ce-cli containerd.io 使用官方脚本安装 1 curl -fsSL https://get.docker.com | bash -s docker 安装docker-compose 1 apt-get install docker-compose 使用阿里云镜像加速器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sudo mkdir -p /etc/docker vim /etc/docker/daemon.json #输入 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://wzlet8dn.mirror.aliyuncs.com\u0026#34;] } 或者 { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://registry.aliyuncs.com/google_containers\u0026#34;] } sudo systemctl daemon-reload sudo systemctl restart docker 使用腾讯云镜像加速器 1 2 3 4 5 6 7 8 9 10 11 12 sudo mkdir -p /etc/docker vim /etc/docker/daemon.json #输入 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34; ] } sudo systemctl daemon-reload sudo systemctl restart docker docker解除sudo限制 1 2 3 sudo usermod -aG docker $USER newgrp docker sudo systemctl restart docker 常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #查看本地镜像 docker images #删除本地镜像 docker image rm [name/id] docker rmi [name/id] #查看镜像详情 docker inspect [name/id] #使用commit创建image docker commit [name/id] test:latest #使用dockerfile构建image docker build -t test:latest dockerfile . #查看所有容器 docker ps -a docker container ls #删除容器 docker rm [name/id] #镜像改名或者改标签 docker tag test:latest #标记本地镜像，将其归入某一仓库。 docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] #镜像搜索 docker search [image] #上传镜像 docker push [image] #下载镜像 docker pull [image] #一键清理退出的容器 docker rm $(docker ps -qf status=exited) docker container prune Dockerfile常用指令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 FROM 指定 base 镜像。 MAINTAINER 设置镜像的作者，可以是任意字符串。 COPY 将文件从 build context 复制到镜像。 COPY 支持两种形式： COPY src dest COPY [\u0026#34;src\u0026#34;, \u0026#34;dest\u0026#34;] 注意：src 只能指定 build context 中的文件或目录。 ADD 与 COPY 类似，从 build context 复制文件到镜像。不同的是，如果 src 是归档文件（tar, zip, tgz, xz 等），文件会被自动解压到 dest。 ENV 设置环境变量，环境变量可被后面的指令使用。例如： ENV MY_VERSION 1.3 RUN apt-get install -y mypackage=$MY_VERSION EXPOSE 指定容器中的进程会监听某个端口，Docker 可以将该端口暴露出来。我们会在容器网络部分详细讨论。 VOLUME 将文件或目录声明为 volume。我们会在容器存储部分详细讨论。 WORKDIR 为后面的 RUN, CMD, ENTRYPOINT, ADD 或 COPY 指令设置镜像中的当前工作目录。 RUN 在容器中运行指定的命令。 CMD 容器启动时运行指定的命令。 Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效。CMD 可以被 docker run 之后的参数替换。 ENTRYPOINT 设置容器启动时运行的命令。 Dockerfile 中可以有多个 ENTRYPOINT 指令，但只有最后一个生效。CMD 或 docker run 之后的参数会被当做参数传递给 ENTRYPOINT。 RUN、CMD和ENTRYPOINT 区别\nRUN 执行命令并创建新的镜像层，RUN 经常用于安装软件包。\nCMD 设置容器启动后默认执行的命令及其参数，但 CMD 能够被 docker run 后面跟的命令行参数替换。\nENTRYPOINT 配置容器启动时运行的命令。\nShell 和 Exec 格式\n可用两种方式指定 RUN、CMD 和 ENTRYPOINT 要运行的命令：Shell 格式和 Exec 格式，二者在使用上有细微的区别。\nShell 格式\n\u0026lt;instruction\u0026gt; \u0026lt;command\u0026gt;\n例如：\n1 2 3 4 5 RUN apt-get install python3 CMD echo \u0026#34;Hello world\u0026#34; ENTRYPOINT echo \u0026#34;Hello world\u0026#34; 当指令执行时，shell 格式底层会调用 /bin/sh -c 。\n例如下面的 Dockerfile 片段：\n1 2 3 ENV name Cloud Man ENTRYPOINT echo \u0026#34;Hello, $name\u0026#34; 执行 docker run 将输出：\n1 Hello, Cloud Man 注意环境变量 name 已经被值 Cloud Man 替换。\n下面来看 Exec 格式。\nExec 格式\n\u0026lt;instruction\u0026gt; [\u0026quot;executable\u0026quot;, \u0026quot;param1\u0026quot;, \u0026quot;param2\u0026quot;, ...]\n例如：\n1 2 3 4 5 RUN [\u0026#34;apt-get\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;python3\u0026#34;] CMD [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello world\u0026#34;] ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello world\u0026#34;] 当指令执行时，会直接调用 \u0026lt;command\u0026gt;，不会被 shell 解析。 例如下面的 Dockerfile 片段：\n1 2 3 ENV name Cloud Man ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello, $name\u0026#34;] 运行容器将输出：\n1 Hello, $name 注意环境变量“name”没有被替换。 如果希望使用环境变量，照如下修改\n1 2 3 ENV name Cloud Man ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo Hello, $name\u0026#34;] 运行容器将输出：\n1 Hello, Cloud Man ==CMD 和 ENTRYPOINT 推荐使用 Exec 格式，因为指令可读性更强，更容易理解。**RUN **则两种格式都可以。==\nRUN RUN 指令通常用于安装应用和软件包。\nRUN 在当前镜像的顶部执行命令，并通过创建新的镜像层。Dockerfile 中常常包含多个 RUN 指令。\nRUN 有两种格式：\n1 2 3 Shell 格式：RUN Exec 格式：RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] 下面是使用 RUN 安装多个包的例子：\n1 2 3 4 5 6 7 8 9 10 11 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion CMD CMD 指令允许用户指定容器的默认执行的命令。\n此命令会在容器启动且 docker run 没有指定其他命令时运行。\n如果 docker run 指定了其他命令，CMD 指定的默认命令将被忽略。 如果 Dockerfile 中有多个 CMD 指令，只有最后一个 CMD 有效。 CMD 有三种格式： Exec 格式：CMD [\u0026ldquo;executable\u0026rdquo;,\u0026ldquo;param1\u0026rdquo;,\u0026ldquo;param2\u0026rdquo;] 这是 CMD 的推荐格式。 CMD [\u0026ldquo;param1\u0026rdquo;,\u0026ldquo;param2\u0026rdquo;] 为 ENTRYPOINT 提供额外的参数，此时 ENTRYPOINT 必须使用 Exec 格式。 Shell 格式：CMD command param1 param2 ENTRYPOINT ENTRYPOINT 指令可让容器以应用程序或者服务的形式运行。\nENTRYPOINT 看上去与 CMD 很像，它们都可以指定要执行的命令及其参数。不同的地方在于 ENTRYPOINT 不会被忽略，一定会被执行，即使运行 docker run 时指定了其他命令。\nENTRYPOINT 有两种格式：\nExec 格式：ENTRYPOINT [\u0026ldquo;executable\u0026rdquo;, \u0026ldquo;param1\u0026rdquo;, \u0026ldquo;param2\u0026rdquo;] 这是 ENTRYPOINT 的推荐格式。 Shell 格式：ENTRYPOINT command param1 param2 在为 ENTRYPOINT 选择格式时必须小心，因为这两种格式的效果差别很大。 Exec 格式\nENTRYPOINT 的 Exec 格式用于设置要执行的命令及其参数，同时可通过 CMD 提供额外的参数。\nENTRYPOINT 中的参数始终会被使用，而 CMD 的额外参数可以在容器启动时动态替换掉。\n比如下面的 Dockerfile 片段：\n1 2 3 ENTRYPOINT [\u0026#34;/bin/echo\u0026#34;, \u0026#34;Hello\u0026#34;] CMD [\u0026#34;world\u0026#34;] 当容器通过 docker run -it [image] 启动时，输出为：\n1 Hello world 而如果通过 docker run -it [image] CloudMan 启动，则输出为：\n1 Hello CloudMan Shell 格式\nENTRYPOINT 的 Shell 格式会忽略任何 CMD 或 docker run 提供的参数。\n总结 使用 RUN 指令安装应用和软件包，构建镜像。 如果 Docker 镜像的用途是运行应用程序或服务，比如运行一个 MySQL，应该优先使用 Exec 格式的 ENTRYPOINT 指令。CMD 可为 ENTRYPOINT 提供额外的默认参数，同时可利用 docker run 命令行替换默认参数。 如果想为容器设置默认的启动命令，可使用 CMD 指令。用户可在 docker run 命令行中替换此默认命令。 网络 docker的网络类型 none host bridge joined container 自定义网络 除了 none, host, bridge 这三个自动创建的网络，用户也可以根据业务需要创建 user-defined 网络。Docker 提供三种 user-defined 网络驱动：bridge, overlay 和 macvlan。overlay 和 macvlan 用于创建跨主机的网络。\n1 docker network create --driver bridge my_net 容器间通信 IP 通信 同一IP段的容器可直接通信。不同IP段的容器需加入同一网关才可通信。两个容器要能通信，必须要有属于同一个网络的网卡。\nDocker DNS Server docker daemon 实现了一个内嵌的 DNS server，使容器可以直接通过“容器名”通信。使用 docker DNS 有个限制：只能在 user-defined 网络中使用。例子：\n1 2 3 docker run -it --network=my_net --name=bbox1 busybox docker run -it --network=my_net --name=bbox2 busybox joined container joined 容器非常特别，它可以使两个或多个容器共享一个网络栈，共享网卡和配置信息，joined 容器之间可以通过 127.0.0.1 直接通信。\n1 docker run -it --network=container:test busybox 存储 docker的存储类型 bind mount 挂载host的目录 docker managed volume 容器管理存储 docker共享数据 bind mount挂载host同一个目录实现共享 volume container 是专门为其他容器提供 volume 的容器。它提供的卷可以是 bind mount，也可以是 docker managed volume。其他容器可以通过 \u0026ndash;volumes-from 使用volume container来实现数据共享。 data-packed volume container 将volume container制作成image，通过docker managed volume 共享数据\n日志 docker logs options:\n1 2 3 4 5 -f, --follow Follow log output --since string Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) -n, --tail string Number of lines to show from the end of the logs (default \u0026#34;all\u0026#34;) -t, --timestamps Show timestamps --until string Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes) 例子：\n1 2 # 类似tail -f docker logs -f containID ","date":"2023-01-01T00:00:00Z","permalink":"https://blog.jklash.com/p/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Docker学习笔记"},{"content":"1.环境准备 node.js (node.js安装教程) nginx (使用宝塔安装) 2.安装Hexo 1 npm install hexo-cli -g 3.配置Hexo 创建第一个Blog 1 2 3 hexo init blog cd blog npm install 启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 npm install hexo --save #清理 hexo clean #生成静态文件 hexo g hexo generate #安装部署插件 npm install hexo-deployer-git --save #推送远程 hexo d hexo deploy #启动服务 hexo s hexo server 主题配置 hexo官方主题仓库地址：https://hexo.io/themes/\n主题推荐：butterfly\n1 2 3 4 5 6 #将主题解压至博客的themes目录下 tar -zxvf hexo-theme-butterfly-XXX.tar.gz -C themes #修改config.yml #添加或者修改, 和themes目录下的主题目录名一致 theme: butterfly 4.发布 方法1: 使用git自动发布到本地和GitHub Page 1 2 3 mkdir git cd git git init --bare blog.git 配置 git hook, 在 blog.git/hooks 目录下新建一个post-receive文件, 然后输入以下内容:\n1 2 #!/bin/bash git --work-tree=blog --git-dir=/git/blog.git checkout -f 然后添加权限\n1 chmod +x blog.git/hooks/post-receive 示例\n1 2 #!/bin/bash git --work-tree=/www/wwwroot/hexo/blog --git-dir=/www/wwwroot/hexo/git/blog.git checkout -f 修改配置\n修改config.yml, 绑定git仓库\n1 2 3 4 5 6 deploy: type: \u0026#39;git\u0026#39; repo: github: github仓库地址 #可选 local: 本地仓库地址 branch: master 示例\n1 2 3 4 5 6 7 deploy: type: \u0026#39;git\u0026#39; repo: github: https://xxxxx@github.com/jklash1996/jklash1996.github.io.git coding: https://xxxxx@e.coding.net/jklash/jklash-hexo/blog.git local: root@ipaddr:/www/wwwroot/hexo/git/blog branch: master 方法2: 使用GitHub Action自动部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 name: Deploy Hexo on: push: branches: - master jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 with: submodules: \u0026#34;true\u0026#34; - name: Install Node.js uses: actions/setup-node@v3 with: node-version: \u0026#34;18.x\u0026#34; - name: Install Hexo run: | npm install hexo-cli -g npm install hexo --save npm install hexo-deployer-git --save - name: Install dependencies run: | npm install npm ci - name: Generate static files run: | hexo clean hexo generate - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.GH_TOKEN }} publish_dir: ./public external_repository: username/username.github.io publish_branch: main 5.常见错误 如果在window下使用hexo, window下执行hexo出现错误 hexo : 无法加载文件C:\\Users\\imwan\\AppData\\Roaming\\npm\\hexo.ps1，因为在此系统上禁止运行脚本。\n解决方法：\ncmd输入\n1 set-ExecutionPolicy RemoteSigned 选择yes\n6.ngnix缓存设置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 location ~* \\.(html|xml)$ { error_log /dev/null; access_log off; add_header Cache-Control no-cache; } location ~* \\.(css|js|png|jpg|jpeg|gif|gz|svg|mp4|mp3|ogg|ogv|webm|htc|woff2|ico|woff|ttf)$ { error_log /dev/null; access_log off; add_header Cache-Control \u0026#34;public,max-age=864000\u0026#34;; } location ~ .*\\.(js|css)?$ { error_log /dev/null; access_log off; add_header Cache-Control no-cache; } ","date":"2023-01-01T00:00:00Z","permalink":"https://blog.jklash.com/p/hexo%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/","title":"Hexo搭建指南"},{"content":"Hugo是一个基于golang的静态博客框架，和Hexo类似\n安装 安装golang Hugo是基于go语言开发的，所以需要安装go才能正常运行\n安装Hugo Linux下安装Hugo\nSnap 1 snap install hugo 安装包安装 前往官方Github下载安装包 1 dpkg -i hugo_extended_0.86.1_Linux-64bit.deb 查看hugo是否安装成功\n1 2 3 hugo version # 输出 hugo v0.86.1-F6821B88+extended linux/amd64 BuildDate=2021-07-30T10:13:35Z VendorInfo=gohugoio 搭建博客 新建博客 1 hugo new site blog 生成一个blog文件夹，就是新建的博客文件夹\n选择主题 Hugo的主题相较于Hexo还是偏少，可前往Hugo主题站选择\n下载主题，以[hugo-theme-stack](https://github.com/CaiJimmy/hugo-theme-stack)为例, 解压至博客根目录下的themes\n1 tar -zxvf hugo-theme-stack-3.11.0.tar.gz -C themes/hugo-themes-stack 修改config.toml\n1 theme = \u0026#34;hugo-theme-stack\u0026#34; # 主题名称，要与主题目录下的文件夹名称一致 主题的功能相关配置可查看themes/hugo-theme-stack/exampleSite/config.toml，将配置项复制到根目录的config.toml即可生效\n编辑文章 1 2 3 # 新建博客文件 hugo new posts/My-First-Post.md # 在content/posts下生成My-First-Post.md文件进行编辑即可 修改默认模版:\n修改archetypes/default.md文件，可自定义模版，下次新建博客文件即可生效\n1 2 3 4 5 6 7 8 --- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} draft: false # ture为草稿，false为正式发布 author: # 作者 tags: # 标签 categories: # 类别 --- 本地测试 1 2 3 4 5 6 7 8 # 默认地址为http://localhost:1313, 运行环境为development hugo serve # 在服务器上可能无法正确访问localhost,因为默认bind的是127.0.0.1, 只允许本地访问。 # 可使用 --bind 绑定0.0.0.0, --baseURL 指定地址为127.0.0.1即可正常访问。 # 使用 -e 指定当前环境。 # -w 参数可实时监控文件变化，用于调试。 # --buildDrafts可显示标记为草稿的文章。 hugo server -w -e production --buildDrafts --bind=\u0026#34;0.0.0.0\u0026#34; --baseURL=http://127.0.0.1:1313/ 编译发布 1 HUGO_ENV=production hugo --gc --minify 生成public文件夹。注意，draft：true的文章不会在public中生成，因为它还是草稿，不会被编译。\n使用algolia搜索进行博客内容搜索 以LoveIt主题的algolia为例\n注册algolia 前往algolia官网注册一个账号 创建一个应用 国内建议选择香港节点 创建一个索引 查看key 安装algolia 使用npm下载安装atomic-algolia，该工具可对索引进行更新\nnpm的安装可查看Linux下node.js安装配置\nnpm install atomic-algolia --save\n修改config.toml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [params.search] enable = true # 搜索引擎的类型 (\u0026#34;lunr\u0026#34;, \u0026#34;algolia\u0026#34;) type = \u0026#34;algolia\u0026#34; # 选择algolia # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \u0026#34;\u0026#34; # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \u0026#34;em\u0026#34; # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \u0026#34;blog\u0026#34; # 索引名称 appID = \u0026#34;HOVR91USRQ\u0026#34; # 应用ID searchKey = \u0026#34;xxx\u0026#34; # algolia搜索api的key # 注意设置outputs，不然index.json不会生成 # Options to make hugo output files # 用于 Hugo 输出文档的设置 [outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;JSON\u0026#34;] page = [\u0026#34;HTML\u0026#34;, \u0026#34;MarkDown\u0026#34;] section = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;] taxonomy = [\u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;] taxonomyTerm = [\u0026#34;HTML\u0026#34;] 配置 创建.env文件 1 2 3 4 ALGOLIA_APP_ID=HOVR91USRQ ALGOLIA_INDEX_NAME=blog ALGOLIA_INDEX_FILE=public/index.json ALGOLIA_ADMIN_KEY=xxx # algolia管理员的key 运行\n1 npm init # 一直回车即可，也可自定义参数 运行atomic-algolia 1 2 3 4 5 # 在 public 生成 index.json hugo # 同步到 algolia, 如果报错提示缺少包，则运行 npm install 安装缺少的包 npm run algolia # 同步完成可在algolia看到索引 此时搜索功能已配置完成，可正常使用\nhugo-theme-stack主题美化 添加回到顶部按钮 编辑主题目录下layouts/_default/single.html\n找到\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 {{ define \u0026#34;main\u0026#34; }} {{ partial \u0026#34;article/article.html\u0026#34; . }} {{ if .Params.links }} {{ partial \u0026#34;article/components/links\u0026#34; . }} {{ end }} {{ partial \u0026#34;article/components/related-contents\u0026#34; . }} {{ if not (eq .Params.comments false) }} {{ partial \u0026#34;comments/include\u0026#34; . }} {{ end }} {{ partialCached \u0026#34;footer/footer\u0026#34; . }} {{ partialCached \u0026#34;article/components/photoswipe\u0026#34; . }} {{ end }} 在 \u0026lt;span class=\u0026quot;ne-text\u0026quot;\u0026gt;{{ partialCached \u0026quot;article/components/photoswipe\u0026quot; . }}\u0026lt;/span\u0026gt;后添加\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;div id=\u0026#34;backTop\u0026#34; onclick=\u0026#34;backTopFunction()\u0026#34; style=\u0026#34;right: 40px; bottom: 40px; display: flex;\u0026#34;\u0026gt; \u0026lt;svg xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34; height=\u0026#34;30\u0026#34; width=\u0026#34;20\u0026#34; viewBox=\u0026#34;0 0 512 512\u0026#34;\u0026gt;\u0026lt;title\u0026gt;Caret Up\u0026lt;/title\u0026gt; \u0026lt;path d=\u0026#34;M414 321.94L274.22 158.82a24 24 0 00-36.44 0L98 321.94c-13.34 15.57-2.28 39.62 18.22 39.62h279.6c20.5 0 31.56-24.05 18.18-39.62z\u0026#34; fill=\u0026#34;#adb5bd\u0026#34;\u0026gt;\u0026lt;/path\u0026gt; \u0026lt;/svg\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; #backTop { position: fixed; background-color: #fff; width: 40px; height: 40px; border-radius: 50%; display: none; align-items: center; justify-content: center; box-shadow: 0 0 6px rgba(0,0,0,.12); cursor: pointer; z-index: 5; } #backTop:hover { background-color: #f1f4f8; } \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; window.onscroll = function() {scrollFunction()}; function scrollFunction() {console.log(121); if (document.body.scrollTop \u0026gt; 20 || document.documentElement.scrollTop \u0026gt; 20) { document.getElementById(\u0026#34;backTop\u0026#34;).style.display = \u0026#34;flex\u0026#34;; } else { document.getElementById(\u0026#34;backTop\u0026#34;).style.display = \u0026#34;none\u0026#34;; } } function backTopFunction() { document.body.scrollTop = 0; document.documentElement.scrollTop = 0; } \u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; 加载动画 在博客根目录新建layouts/partials/footer目录，在该目录下新建custom.html文件，将下面内容复制进去\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/gh/zhixuan2333/gh-blog@v0.1.0/js/nprogress.min.js\u0026#34; integrity=\u0026#34;sha384-bHDlAEUFxsRI7JfULv3DTpL2IXbbgn4JHQJibgo5iiXSK6Iu8muwqHANhun74Cqg\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/gh/zhixuan2333/gh-blog@v0.1.0/css/nprogress.css\u0026#34; integrity=\u0026#34;sha384-KJyhr2syt5+4M9Pz5dipCvTrtvOmLk/olWVdfhAp858UCa64Ia5GFpTN7+G4BWpE\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;script\u0026gt; NProgress.start(); document.addEventListener(\u0026#34;readystatechange\u0026#34;, () =\u0026gt; { if (document.readyState === \u0026#34;interactive\u0026#34;) NProgress.inc(0.8); if (document.readyState === \u0026#34;complete\u0026#34;) NProgress.done(); }); \u0026lt;/script\u0026gt; 美化滚动条 在博客根目录下新建assets/scss目录，在该目录下新建文件custom.scss，将下面内容复制进去\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 html{ ::-webkit-scrollbar { width: 20px; } ::-webkit-scrollbar-track { background-color: transparent; } ::-webkit-scrollbar-thumb { background-color: #d6dee1; border-radius: 20px; border: 6px solid transparent; background-clip: content-box; } ::-webkit-scrollbar-thumb:hover { background-color: #a8bbbf; } } 使用GitHub Action自动发布 博客根目录下新建.github/workflows/main.yml, 输入以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 name: Deploy Hugo Blog # 自动化部署 Hugo 博客 on: # 触发条件 push: branches: - master # 推送到 master 分支 release: types: - published # 推送新版本号 workflow_dispatch: # 手动触发 jobs: build: name: Build runs-on: ubuntu-latest # 使用Ubuntu最新版作为环境 steps: - name: Checkout # Checkout仓库 uses: actions/checkout@v2 with: ref: master - name: Setup Hugo # 使用预编译的 Hugo 二进制文件 uses: peaceiris/actions-hugo@v2.5.0 with: hugo-version: \u0026#34;latest\u0026#34; extended: true # 使用 Hugo-extended 版本，不想使用extended版本选择false即可 - name: Setup algolia # 使用 npm 安装 algolia run: | npm install atomic-algolia --save - name: Get username.github.io # 获取 username.github.io 以保持 commit 记录 run: | git clone --no-checkout https://github.com/jklash1996/jklash1996.github.io.git public - name: Build # hugo编译完后，生成 index.json， 同步到 algolia run: | HUGO_ENV=production hugo --gc --minify npm run algolia - name: Deploy to server # 使用rsync部署到云服务器，可选 uses: easingthemes/ssh-deploy@v2.1.5 env: ARGS: \u0026#34;-avz --delete\u0026#34; SOURCE: \u0026#34;public/\u0026#34; # 要同步到服务器的目录 REMOTE_HOST: ${{ secrets.SSH_HOST}} # 服务器 IP 地址 REMOTE_USER: ${{ secrets.SSH_USER}} # 服务器 SSH 连接用户名 REMOTE_PORT: ${{ secrets.SSH_PORT}} # 服务器 SSH 端口 SSH_PRIVATE_KEY: ${{ secrets.SSH_KEY}} # 配置在服务器上公钥所对应的私钥 TARGET: ${{ secrets.WEBSITE_PATH}} # 服务器上对应网站的根目录 - name: Publish # 将生成出的站点推向 username.github.io env: USER: username EMAIL: email GH_REF: github.com/username/username.github.io.git GH_TOKEN: ${{ secrets.GH_TOKEN }} run: | cd public git config --global user.name \u0026#34;$USER\u0026#34; git config --global user.email \u0026#34;$EMAIL\u0026#34; export TZ=\u0026#39;Asia/Shanghai\u0026#39; git add . git commit --allow-empty -m \u0026#34;Auto Update: `date +\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;`\u0026#34; git push \u0026#34;https://$USER:$GH_TOKEN@$GH_REF\u0026#34; master:master secrets可在源码仓库Settings中设置, 以保护你的信息不被泄露\n","date":"2023-01-01T00:00:00Z","permalink":"https://blog.jklash.com/p/hugo%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/","title":"Hugo搭建指南"},{"content":"汇总k8s学习过程中的笔记\n基本概念 名词解释 Cluster\nCluster 是计算、存储和网络资源的集合，Kubernetes利用这些资源运行各种基于容器的应用。\nMaster\nMaster 是 Cluster 的大脑，它的主要职责是调度，即决定将应用放在哪里运行。Master 运行 Linux 操作系统，可以是物理机或者虚拟机。为了实现高可用，可以运行多个 Master。\nNode\nNode 的职责是运行容器应用。Node 由 Master 管理，Node 负责监控并汇报容器的状态，并根据 Master 的要求管理容器的生命周期。Node 运行在 Linux 操作系统，可以是物理机或者是虚拟机。\nPod\nPod 是 Kubernetes 的最小工作单元。每个 Pod 包含一个或多个容器。Pod 中的容器会作为一个整体被 Master 调度到一个 Node 上运行。\nKubernetes 引入 Pod 主要基于下面两个目的：\n可管理性 有些容器天生就是需要紧密联系，一起工作。Pod 提供了比容器更高层次的抽象，将它们封装到一个部署单元中。Kubernetes 以 Pod 为最小单位进行调度、扩展、共享资源、管理生命周期。\n通信和资源共享。 Pod 中的所有容器使用同一个网络 namespace，即相同的 IP 地址和 Port 空间。它们可以直接用 localhost 通信。同样的，这些容器可以共享存储，当 Kubernetes 挂载 volume 到 Pod，本质上是将 volume 挂载到 Pod 中的每一个容器。\nPods 有两种使用方式：\n运行单一容器。 one-container-per-Pod 是 Kubernetes 最常见的模型，这种情况下，只是将单个容器简单封装成 Pod。即便是只有一个容器，Kubernetes 管理的也是 Pod 而不是直接管理容器。 运行多个容器。 但问题在于：哪些容器应该放到一个 Pod 中？ 答案是：这些容器联系必须 非常紧密，而且需要 直接共享资源。 Controller\nKubernetes 通常不会直接创建 Pod，而是通过 Controller 来管理 Pod 的。Controller 中定义了 Pod 的部署特性，比如有几个副本，在什么样的 Node 上运行等。为了满足不同的业务场景，Kubernetes 提供了多种 Controller，包括 Deployment、ReplicaSet、DaemonSet、StatefuleSet、Job 等。\nDeployment 是最常用的 Controller，Deployment 可以管理 Pod 的多个副本，并确保 Pod 按照期望的状态运行。\nReplicaSet 实现了 Pod 的多副本管理。使用 Deployment 时会自动创建 ReplicaSet，也就是说 Deployment 是通过 ReplicaSet 来管理 Pod 的多个副本，我们通常不需要直接使用 ReplicaSet。\nDaemonSet 用于每个 Node 最多只运行一个 Pod 副本的场景。正如其名称所揭示的，DaemonSet 通常用于运行 daemon。\nStatefuleSet 能够保证 Pod 的每个副本在整个生命周期中名称是不变的。而其他 Controller 不提供这个功能，当某个 Pod 发生故障需要删除并重新启动时，Pod 的名称会发生变化。同时 StatefuleSet 会保证副本按照固定的顺序启动、更新或者删除。\nJob 用于运行结束就删除的应用。而其他 Controller 中的 Pod 通常是长期持续运行。\nService\nKubernetes Service 定义了外界访问一组特定 Pod 的方式。Service 有自己的 IP 和端口，Service 为 Pod 提供了负载均衡。\nKubernetes 运行容器（Pod）与访问容器（Pod）这两项任务分别由 Controller 和 Service 执行。\nNamespace\nNamespace 可以将一个物理的 Cluster 逻辑上划分成多个虚拟 Cluster，每个 Cluster 就是一个 Namespace。不同 Namespace 里的资源是完全隔离的。\nKubernetes 默认创建了两个 Namespace。\ndefault \u0026ndash; 创建资源时如果不指定，将被放到这个 Namespace 中。 kube-system \u0026ndash; Kubernetes 自己创建的系统资源将放到这个 Namespace 中。 网络模型 为了保证网络方案的标准化、扩展性和灵活性，Kubernetes 采用了 Container Networking Interface（CNI）规范。\nCNI 是由 CoreOS 提出的容器网络规范，它使用了插件（Plugin）模型创建容器的网络栈。\n目前已有多种支持 Kubernetes 的网络方案，比如 Flannel、Calico、Canal、Weave Net 等。因为它们都实现了 CNI 规范，用户无论选择哪种方案，得到的网络模型都一样，即每个 Pod 都有独立的 IP，可以直接通信。区别在于不同方案的底层实现不同。\nk8s架构 架构图：\nmaster Master 是 Kubernetes Cluster 的大脑，运行着如下 Daemon 服务：kube-apiserver、kube-scheduler、kube-controller-manager、etcd 和 Pod 网络（例如 flannel）。\nAPI Server（kube-apiserver）\nAPI Server 提供 HTTP/HTTPS RESTful API，即 Kubernetes API。API Server 是 Kubernetes Cluster 的前端接口，各种客户端工具（CLI 或 UI）以及 Kubernetes 其他组件可以通过它管理 Cluster 的各种资源。\nScheduler（kube-scheduler）\nScheduler 负责决定将 Pod 放在哪个 Node 上运行。Scheduler 在调度时会充分考虑 Cluster 的拓扑结构，当前各个节点的负载，以及应用对高可用、性能、数据亲和性的需求。\nController Manager（kube-controller-manager）\nController Manager 负责管理 Cluster 各种资源，保证资源处于预期的状态。Controller Manager 由多种 controller 组成，包括 replication controller、endpoints controller、namespace controller、serviceaccounts controller 等。\n不同的 controller 管理不同的资源。例如 replication controller 管理 Deployment、StatefulSet、DaemonSet 的生命周期，namespace controller 管理 Namespace 资源。\netcd\netcd 负责保存 Kubernetes Cluster 的配置信息和各种资源的状态信息。当数据发生变化时，etcd 会快速地通知 Kubernetes 相关组件。\nPod 网络\nPod 要能够相互通信，Kubernetes Cluster 必须部署 Pod 网络，flannel 是其中一个可选方案。\nnode Node 是 Pod 运行的地方，Kubernetes 支持 Docker、rkt 等容器 Runtime。 Node上运行的 Kubernetes 组件有 kubelet、kube-proxy 和 Pod 网络（例如 flannel）。\nkubelet\nkubelet 是 Node 的 agent，当 Scheduler 确定在某个 Node 上运行 Pod 后，会将 Pod 的具体配置信息（image、volume 等）发送给该节点的 kubelet，kubelet 根据这些信息创建和运行容器，并向 Master 报告运行状态。\nkube-proxy\nservice 在逻辑上代表了后端的多个 Pod，外界通过 service 访问 Pod。service 接收到的请求是如何转发到 Pod 的呢？这就是 kube-proxy 要完成的工作。\n每个 Node 都会运行 kube-proxy 服务，它负责将访问 service 的 TCP/UPD 数据流转发到后端的容器。如果有多个副本，kube-proxy 会实现负载均衡。\nPod 网络\nPod 要能够相互通信，Kubernetes Cluster 必须部署 Pod 网络，flannel 是其中一个可选方案。\n安装 关闭swap 临时关闭\n1 sudo swapoff -a 永久关闭\n1 2 3 sudo vim /etc/fstab ## 注释 #/swap.img none swap sw 0 0 安装kubeadm kubeadm kubectl（国内源） 1 2 3 4 5 6 7 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y ca-certificates curl curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - echo \u0026#34;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\u0026#34; \u0026gt; /etc/apt/sources.list.d/kubernetes.list sudo apt-get update \u0026amp;\u0026amp; apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl 下载k8s镜像（国内源） 使用脚本一键下载并更名\n1 2 3 4 5 6 7 8 9 10 11 12 #!/usr/bin/env bash docker image pull \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.8.0\u0026#34; docker image tag \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.8.0\u0026#34; docker image rmi \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.8.0\u0026#34; for IT in etcd:3.4.13-0 pause:3.4.1 kube-proxy:v1.21.3 kube-scheduler:v1.21.3 kube-controller-manager:v1.21.3 kube-apiserver:v1.21.3 do docker image pull \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/$IT\u0026#34; docker image tag \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/$IT\u0026#34; \u0026#34;k8s.gcr.io/$IT\u0026#34; docker image rmi \u0026#34;registry.cn-hangzhou.aliyuncs.com/google_containers/$IT\u0026#34; done 部署 初始化Master 1 kubeadm init --apiserver-advertise-address [k8s-master ip] --pod-network-cidr=10.244.0.0/16 过程：\nkubeadm 执行初始化前的检查。 生成 token 和证书。 生成 KubeConfig 文件，kubelet 需要这个文件与 Master 通信。 安装 Master 组件，会从 goolge 的 Registry 下载组件的 Docker 镜像，这一步可能会花一些时间，主要取决于网络质量。 安装附加组件 kube-proxy 和 kube-dns。 Kubernetes Master 初始化成功。 提示如何配置 kubectl。 提示如何安装 Pod 网络。 提示如何注册其他节点到 Cluster。 配置kubectl 1 2 3 4 5 6 7 mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config # 命令补全 apt-get -y install bash-completion echo \u0026#34;source \u0026lt;(kubectl completion bash)\u0026#34; \u0026gt;\u0026gt; ~/.bashrc kubectl常用命令 logs：查看POD或容器的日志\n1 2 3 4 5 6 7 8 #查看POD中所有容器的日志 kubectl logs nginxpod #查看POD中指定容器的日志 kubectl logs nginxpod -c nginx #查看指定名称空间中的POD中的指定容器日志 kubectl logs -n test mysqlpod -c mysql describe：显示资源运行状态信息\n1 2 3 4 5 6 kubectl describe pod \u0026lt;Pod Name\u0026gt; #查看指定名称空间的POD kubectl describe pods nginxpod kubectl describe pods mysql -n test kubectl describe pod kube-flannel-ds-v0p3x --namespace=kube-system exec：在POD中执行命令\n1 2 3 4 5 6 7 8 9 #此方式只适用于POD只有一个容器时 kubectl exec -it nginxpod -- /bin/bash #如POD中有多个容器需要使用-c选项指定容器 kubectl exec -it nginxpod -c nginx -- /bin/bash #一次性执行多个命令或使用管道符 kubectl exec nfs -- sh -c \u0026#34;echo \u0026#39;SET testkey www.linux321.com\u0026#39; | redis-cli\u0026#34; kubectl exec nfs -- sh -c \u0026#34;echo \u0026#39;GET testkey\u0026#39; | redis-cli\u0026#34; 查看资源类型\n1 kubectl api-resouurce 查看名称空间\n1 kubectl get namespaces 查看节点状态\n1 2 #在master上执行 kubectl get nodes 查看pod状态\n1 2 kubectl get pod --all-namespaces kubectl get po -A 部署flannel 1 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 国内镜像仓库手动下载flannel\n1 docker pull registry.cn-hangzhou.aliyuncs.com/k8sos/flannel:v0.14.0 子节点加入Master 查看现有token\n1 kubeadm token list 生成一个新token\n1 2 3 kubeadm token create --print-join-command # 默认有效期24小时,若想久一些可以结合--ttl参数,设为0则用不过期 kubeadm token create --ttl 0 查看ca证书的hash\n1 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u0026gt;/dev/null | openssl dgst -sha256 -hex | sed \u0026#39;s/^.* //\u0026#39; node加入Master\n1 kubeadm join [k8s-master ip]:6443 --token [token] --discovery-token-ca-cert-hash [ca cert] 子节点需要的镜像\nflannel pause k8s-proxy 查看节点状态\n1 2 3 #在master上执行 kubectl get nodes #都处于ready状态，说明node节点已可用 查看pod状态\n1 2 kubectl get pod --all-namespaces kubectl get po -A 查看pod运行情况\n1 2 kubectl describe pod kube-flannel-ds-v0p3x --namespace=kube-system #如果镜像已经都下载好还没处于ready状态，可尝试重启容器服务systemctl restart docker 删除节点 应首先清空节点并确保该节点为空， 然后取消配置该节点。\n使用适当的凭证与控制平面节点通信，运行：\n1 kubectl drain \u0026lt;node name\u0026gt; --delete-local-data --force --ignore-daemonsets 在删除节点之前，请重置 kubeadm 安装的状态：\n1 kubeadm reset 重置过程不会重置或清除 iptables 规则或 IPVS 表。如果你希望重置 iptables，则必须手动进行：\n1 iptables -F \u0026amp;\u0026amp; iptables -t nat -F \u0026amp;\u0026amp; iptables -t mangle -F \u0026amp;\u0026amp; iptables -X 如果要重置 IPVS 表，则必须运行以下命令：\n1 ipvsadm -C 现在删除节点：\n1 kubectl delete node \u0026lt;node name\u0026gt; 运行应用 命令运行 创建应用\nmaster先下载nginx镜像\n1 2 3 4 kubectl create deployment NAME --image=image -- [COMMAND] [args...] [options] kubectl create deployment nginx --image=\u0026#34;nginx:1.18.0\u0026#34; #或者 kubectl run deployment nginx --image=\u0026#34;nginx:1.21.1\u0026#34; 删除应用\n1 kubectl delete deployment/nginx 查看pod\n1 2 3 kubectl get pods #查看详细信息 kubectl describe pod 删除pod\n1 2 3 4 5 6 7 kubectl delete pods #删除所有POD kubectl delete pods --all #删除指定多个POD kubectl delete pods nginxpod demoapp 查看容器调度\n1 kubectl get pods -o wide 拓展实例\n1 kubectl scale deployment nginx --replicas=3 查看ReplicaSet\n1 kubectl get replicaset 配置运行 创建Deployment的yml文件\n常用字段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: apps/v1 # API群组及版本 kind: Deployment # 资源类型特有标识 metadata: name \u0026lt;string\u0026gt; # 资源名称，在作用域中要唯一 namespace \u0026lt;string\u0026gt; # 名称空间；Deployment隶属名称空间级别 spec: minReadySeconds \u0026lt;integer\u0026gt; # Pod就绪后多少秒内任一容器无crash方可视为“就绪” replicas \u0026lt;integer\u0026gt; # 期望的Pod副本数，默认为1 selector \u0026lt;object\u0026gt; # 标签选择器，必须匹配template字段中Pod模板中的标签 template \u0026lt;object\u0026gt; # Pod模板对象 revisionHistoryLimit \u0026lt;integer\u0026gt; # 滚动更新历史记录数量，默认为10 strategy \u0026lt;Object\u0026gt; # 滚动更新策略 type \u0026lt;string\u0026gt; # 滚动更新类型，可用值有Recreate和RollingUpdate； rollingUpdate \u0026lt;Object\u0026gt; # 滚动更新参数，专用于RollingUpdate类型 maxSurge \u0026lt;string\u0026gt; # 更新期间可比期望的Pod数量多出的数量或比例； maxUnavailable \u0026lt;string\u0026gt; # 更新期间可比期望的Pod数量缺少的数量或比例，10， progressDeadlineSeconds \u0026lt;integer\u0026gt; # 滚动更新故障超时时长，默认为600秒 paused \u0026lt;boolean\u0026gt; # 是否暂停部署过程 执行apply命令运行\n1 kubectl apply -f deployment.yml ","date":"2023-01-01T00:00:00Z","permalink":"https://blog.jklash.com/p/kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Kubernetes学习笔记"}]